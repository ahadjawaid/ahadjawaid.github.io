<!DOCTYPE html> <html lang="en"> <head> <meta http-equiv="Content-Type" content="text/html; charset=UTF-8"> <meta charset="utf-8"> <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no"> <meta http-equiv="X-UA-Compatible" content="IE=edge"> <title> Introduction to Deep Reinforcement Learning | Ahad Jawaid </title> <meta name="author" content="Ahad Jawaid"> <meta name="description" content="My notes on Deep Reinforcement Learning (DRL) based on the first chapter of the 'Grokking Deep Reinforcement Learning' by Miguel Morales."> <link rel="stylesheet" href="/assets/css/bootstrap.min.css?a4b3f509e79c54a512b890d73235ef04"> <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/css/mdb.min.css" integrity="sha256-jpjYvU3G3N6nrrBwXJoVEYI/0zw8htfFnhT9ljN3JJw=" crossorigin="anonymous"> <link defer rel="stylesheet" href="/assets/css/academicons.min.css?f0b7046b84e425c55f3463ac249818f5"> <link defer rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Roboto:300,400,500,700|Roboto+Slab:100,300,400,500,700|Material+Icons&amp;display=swap"> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-github.css?591dab5a4e56573bf4ef7fd332894c99" media="" id="highlight_theme_light"> <link rel="shortcut icon" href="data:image/svg+xml,&lt;svg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20100%20100%22&gt;&lt;text%20y=%22.9em%22%20font-size=%2290%22&gt;%F0%9F%92%A1&lt;/text&gt;&lt;/svg&gt;"> <link rel="stylesheet" href="/assets/css/main.css?d41d8cd98f00b204e9800998ecf8427e"> <link rel="canonical" href="https://ahadjawaid.github.io/blog/2023/introduction-to-deep-reinforcement-learning/"> <script src="/assets/js/theme.js?9a0c749ec5240d9cda97bc72359a72c0"></script> <link defer rel="stylesheet" href="/assets/css/jekyll-pygments-themes-native.css?5847e5ed4a4568527aa6cfab446049ca" media="none" id="highlight_theme_dark"> <script>initTheme();</script> </head> <body class="fixed-top-nav "> <header> <nav id="navbar" class="navbar navbar-light navbar-expand-sm fixed-top" role="navigation"> <div class="container"> <a class="navbar-brand title font-weight-lighter" href="/"> Ahad Jawaid </a> <button class="navbar-toggler collapsed ml-auto" type="button" data-toggle="collapse" data-target="#navbarNav" aria-controls="navbarNav" aria-expanded="false" aria-label="Toggle navigation"> <span class="sr-only">Toggle navigation</span> <span class="icon-bar top-bar"></span> <span class="icon-bar middle-bar"></span> <span class="icon-bar bottom-bar"></span> </button> <div class="collapse navbar-collapse text-right" id="navbarNav"> <ul class="navbar-nav ml-auto flex-nowrap"> <li class="nav-item "> <a class="nav-link" href="/">about </a> </li> <li class="nav-item active"> <a class="nav-link" href="/blog/">blog </a> </li> <li class="nav-item "> <a class="nav-link" href="/publications/">publications </a> </li> <li class="nav-item "> <a class="nav-link" href="/projects/">projects </a> </li> <li class="nav-item "> <a class="nav-link" href="/cv/">cv </a> </li> <li class="nav-item "> <a class="nav-link" href="/teaching/">teaching </a> </li> <li class="nav-item"> <button id="search-toggle" title="Search" onclick="openSearchModal()"> <span class="nav-link">ctrl k <i class="ti ti-search"></i></span> </button> </li> <li class="toggle-container"> <button id="light-toggle" title="Change theme"> <i class="ti ti-sun-moon" id="light-toggle-system"></i> <i class="ti ti-moon-filled" id="light-toggle-dark"></i> <i class="ti ti-sun-filled" id="light-toggle-light"></i> </button> </li> </ul> </div> </div> </nav> <progress id="progress" value="0"> <div class="progress-container"> <span class="progress-bar"></span> </div> </progress> </header> <div class="container mt-5" role="main"> <div class="post"> <header class="post-header"> <h1 class="post-title">Introduction to Deep Reinforcement Learning</h1> <p class="post-meta"> Created in June 27, 2023 by Ahad Jawaid </p> <p class="post-tags"> <a href="/blog/2023"> <i class="fa-solid fa-calendar fa-sm"></i> 2023 </a>   ·   <a href="/blog/category/deep-reinforcement-learning"> <i class="fa-solid fa-tag fa-sm"></i> Deep Reinforcement Learning</a>   <a href="/blog/category/notes"> <i class="fa-solid fa-tag fa-sm"></i> Notes</a> </p> </header> <article class="post-content"> <div id="markdown-content"> <style>.responsive-img{width:100%}@media(min-width:992px){.responsive-img{width:75%}}</style> <h2 id="artificial-intelligence-ai">Artificial Intelligence (AI)</h2> <ul> <li>Artificial Intelligence (AI) is a domain of computer science dedicated to developing software capable of exhibiting attributes of intelligence.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/introduction-to-deep-reinforcement-learning/subfields_of_artificial_intelligence.jpg" sizes="95vw"></source> <img src="/assets/img/posts/introduction-to-deep-reinforcement-learning/subfields_of_artificial_intelligence.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="machine-learning-ml">Machine Learning (ML)</h2> <ul> <li>Machine learning, a subset of AI, tackles problems necessitating intelligent solutions by learning from data.</li> <li> <strong>Supervised Learning (SL):</strong> A method that learns from labeled data. <ul> <li>E.g., handwritten-digit-recognition</li> </ul> </li> <li> <strong>Unsupervised Learning (UL):</strong> A method that learns from unlabeled data <ul> <li>E.g., customer segmentaiton</li> </ul> </li> <li> <strong>Reinforcement Learning (RL):</strong> A method that learns from trial and error <ul> <li>E.g., pong-playing agent</li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/introduction-to-deep-reinforcement-learning/main_branches_of_machine_learning.jpg" sizes="95vw"></source> <img src="/assets/img/posts/introduction-to-deep-reinforcement-learning/main_branches_of_machine_learning.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h2 id="deep-learning-dl">Deep Learning (DL)</h2> <ul> <li>Deep Learning employs multi-layered non-linear function approximations, also known as neural networks, to address ML tasks. Essentially, it is a suite of techniques that utilize neural networks to solve ML challenges.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/introduction-to-deep-reinforcement-learning/deep_learning_is_a_powerful_toolbox.jpg" sizes="95vw"></source> <img src="/assets/img/posts/introduction-to-deep-reinforcement-learning/deep_learning_is_a_powerful_toolbox.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="deep-reinforcement-learning-drl">Deep Reinforcement Learning (DRL)</h3> <ul> <li>Deep Reinforcement Learning learns through trial and error from feedback that’s simultaneously sequentially, evaluative, and sampled by leveraging non-linear function approximation (neural networks).</li> </ul> <h2 id="reinforcement-learning-rl">Reinforcement Learning (RL)</h2> <h3 id="similar-fields">Similar fields</h3> <ul> <li> <strong>Reinforcement Learning (RL):</strong> Investigates methods of resolving complex sequential decision-making problems under uncertain conditions.</li> <li> <strong>Control Theory (CT)</strong>: Examines methods of controlling complex known dynamic systems.</li> <li> <strong>Operations Research (OR)</strong>: Investigates decision-making under uncertain conditions, generally featuring a larger action space than in DRL.</li> <li> <strong>Psychology</strong>: Studies human behavior, which frequently encapsulates complex sequential decision-making problems under uncertainty.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/introduction-to-deep-reinforcement-learning/the_synergy_between_similar_fields.jpg" sizes="95vw"></source> <img src="/assets/img/posts/introduction-to-deep-reinforcement-learning/the_synergy_between_similar_fields.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="agent-and-enviroment">Agent and Enviroment</h3> <ul> <li> <strong>Agent:</strong> Refers exclusively to the decision-making entity. <ul> <li>For instance, if you are training a robot arm to pick up a toy, the agent is the code that makes the decisions, not the robot arm itself.</li> </ul> </li> <li> <strong>Environment:</strong> Includes everything external to the agent, beyond the agent’s control, and everything that follows the agent’s decisions. <ul> <li>In the context of training a robot arm to pick up a toy, the objects to be picked up, the tray where the objects reside, atmospheric conditions like wind, and even the robot arm itself are all considered parts of the environment.</li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/introduction-to-deep-reinforcement-learning/boundary_between_agent_and_environment.jpg" sizes="95vw"></source> <img src="/assets/img/posts/introduction-to-deep-reinforcement-learning/boundary_between_agent_and_environment.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="states-and-observations">States and Observations</h3> <ul> <li> <strong>State Space:</strong> The set of all possible variables and values that can represent the state of the environment.</li> <li> <strong>State:</strong> A comprehensive description of the environment, or an instantiation of the state space.</li> <li> <strong>Observation:</strong> A partial or incomplete description of the environment.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/introduction-to-deep-reinforcement-learning/states_vs_observations.jpg" sizes="95vw"></source> <img src="/assets/img/posts/introduction-to-deep-reinforcement-learning/states_vs_observations.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="reinforcement-learning-cycle">Reinforcement Learning Cycle</h3> <ul> <li> <strong>Transition Function:</strong> The mapping from the agent’s action to a potentially new state.</li> <li> <strong>Reward Function:</strong> The mapping from the action taken to the potential reward signal. <ul> <li>Goals are defined via the reward function.</li> </ul> </li> <li> <strong>Model:</strong> A set of the transitions and rewards.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/introduction-to-deep-reinforcement-learning/the_reinforcement_learning_cycle.jpg" sizes="95vw"></source> <img src="/assets/img/posts/introduction-to-deep-reinforcement-learning/the_reinforcement_learning_cycle.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h4 id="agents-improvement-process">Agent’s Improvement process:</h4> <ol> <li>Interact with the environment.</li> <li>Evaluates its behavior.</li> <li>Improves its responses.</li> </ol> <h4 id="agents-can-be-designed-to-learn">Agent’s can be designed to learn:</h4> <ul> <li> <strong>Policy:</strong> The mapping from observations to actions.</li> <li> <strong>Models:</strong> A model of the environment on mappings.</li> <li> <strong>Value Functions:</strong> The mapping of a state to its estimated value.</li> </ul> <h3 id="experiences">Experiences</h3> <ul> <li> <strong>Time Step:</strong> A single cycle of interaction between the agent and the environment.</li> <li> <strong>Experience:</strong> The set consisting of the state, the action, the reward, and the new state in a single time step.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/introduction-to-deep-reinforcement-learning/experience_tuples.jpg" sizes="95vw"></source> <img src="/assets/img/posts/introduction-to-deep-reinforcement-learning/experience_tuples.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> <strong>Episodic Task:</strong> Tasks that have a natural ending or goes on finitely many step. <ul> <li>E.g., video games</li> </ul> </li> <li> <strong>Continuing Task:</strong> Tasks that don’t have a natural ending or could go on indefinitely. <ul> <li>E.g., learning forward motion</li> </ul> </li> </ul> <h3 id="credit-assignment-problem">Credit Assignment Problem</h3> <ul> <li> <strong>Temporal Credit Assignment Problem:</strong> the challenge in determining which state and/or action is responsible for a reward the agent recieves <ul> <li>Usually occurs when the agent may have delayed rewards from an action or state that caused it hence the temporal aspect of the problem</li> </ul> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/introduction-to-deep-reinforcement-learning/temporal_credit_assignment_problem.jpg" sizes="95vw"></source> <img src="/assets/img/posts/introduction-to-deep-reinforcement-learning/temporal_credit_assignment_problem.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="exploration-vs-exploitation">Exploration vs. Exploitation</h3> <ul> <li> <strong>Evaluative Feedback:</strong> Feedback that provides an indication of performance but not correctness.</li> <li> <strong>Exploration versus Exploitation trade-off:</strong> The balance between collecting new information from the environment and using known information to maximize rewards.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/introduction-to-deep-reinforcement-learning/exploration_vs_exploitation.jpg" sizes="95vw"></source> <img src="/assets/img/posts/introduction-to-deep-reinforcement-learning/exploration_vs_exploitation.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="sampled-feedback">Sampled Feedback</h3> <ul> <li>Learning from sparse or weak feedback becomes more challenging with samples only. The agent must be capable of generalizing to learn from sampled feedback.</li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/introduction-to-deep-reinforcement-learning/learning_from_sampled_feedback.jpg" sizes="95vw"></source> <img src="/assets/img/posts/introduction-to-deep-reinforcement-learning/learning_from_sampled_feedback.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <h3 id="types-of-agents">Types of Agents</h3> <ul> <li> <strong>Policy-based:</strong> Designed to approximate policies.</li> <li> <strong>Model-based:</strong> Designed to approximate models.</li> <li> <strong>Value-based:</strong> Designed to approximate value functions.</li> <li> <strong>Actor-critic:</strong> Designed to approximate both policies and value functions.</li> </ul> <h3 id="pros-and-cons">Pros and Cons</h3> <p><strong>Strength:</strong> Reinforcement learning excels in mastering specific tasks.</p> <p><strong>Weaknesses:</strong> To learn a well-performing policy, it generally requires millions of samples.</p> <h2 id="history-of-deep-reinforcement-learning">History of Deep Reinforcement Learning</h2> <ul> <li> <p><strong>Alan Turing - 1930:</strong> Developed the Turing Test, a test of a machine’s ability to exhibit intelligent behavior indistinguishable from that of a human.</p> </li> <li> <p><strong>John McCarthy - 1955:</strong> Coined the term “Artificial Intelligence”.</p> </li> <li> <p><strong>Andrew Ng - 2002:</strong> Trained an autonomous helicopter to perform stunts by observing human-expert flights using inverse reinforcement learning.</p> </li> <li> <p><strong>Nate Kohl and Peter Stone - 2002:</strong> Applied policy-gradient methods to train a soccer-playing robot.</p> </li> <li> <p><strong>Mnih et al. - 2013, 2015:</strong> Introduced the DQN algorithm, which learned to play Atari games from raw pixels.</p> </li> </ul> <figure> <picture> <source class="responsive-img-srcset" srcset="/assets/img/posts/introduction-to-deep-reinforcement-learning/atari_dqn.jpg" sizes="95vw"></source> <img src="/assets/img/posts/introduction-to-deep-reinforcement-learning/atari_dqn.jpg" class="img-fluid rounded z-depth-1" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $('.responsive-img-srcset').remove();"> </picture> </figure> <ul> <li> </li> <li> <p><strong>Silver et al. - 2014:</strong> Released the deterministic policy gradient (DPG) algorithm.</p> </li> <li> <p><strong>Lillicrap et al. - 2015:</strong> Improved DPG with deep deterministic policy gradient (DDPG)</p> </li> <li> <p><strong>Schulman et al. - 2016:</strong> Released trust region policy optimization (TRPO) and generalized advantage estimation (GAE) methods.</p> </li> <li> <p><strong>Sergey Levine et al. - 2016:</strong> Published Guided Policy Search (GPS)</p> </li> <li> <p><strong>Silver et al. - 2016:</strong> Demonstrated AlphaGo</p> </li> <li>…</li> </ul> <h2 id="references">References</h2> <p>Morales, M. (2020). Grokking Deep Reinforcement Learning. Originally Published: October 15, 2020.</p> <p><em>All figures are sourced from this book.</em></p> </div> </article> <br> <hr> <br> <ul class="list-disc pl-8"></ul> <h2 class="text-3xl font-semibold mb-4 mt-12">Enjoy Reading This Article?</h2> <p class="mb-2">Here are some more articles you might like to read next:</p> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/modeling-reinforcement-learning-problem/">Modeling the Reinforcement Learning Problem</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/translating-theory-into-code/">From Paper to Code: A Guide to Implement Research</a> </li> <li class="my-2"> <a class="text-pink-700 underline font-semibold hover:text-pink-800" href="/blog/2023/the-universal-function/">Neural network: The universal function</a> </li> </div> </div> <footer class="fixed-bottom" role="contentinfo"> <div class="container mt-0"> © Copyright 2024 Ahad Jawaid. Powered by <a href="https://jekyllrb.com/" target="_blank" rel="external nofollow noopener">Jekyll</a> with <a href="https://github.com/alshedivat/al-folio" rel="external nofollow noopener" target="_blank">al-folio</a> theme. Hosted by <a href="https://pages.github.com/" target="_blank" rel="external nofollow noopener">GitHub Pages</a>. </div> </footer> <script src="https://cdn.jsdelivr.net/npm/jquery@3.6.0/dist/jquery.min.js" integrity="sha256-/xUj+3OJU5yExlq6GSYGSHk7tPXikynS7ogEvDej/m4=" crossorigin="anonymous"></script> <script src="/assets/js/bootstrap.bundle.min.js"></script> <script src="https://cdn.jsdelivr.net/npm/mdbootstrap@4.20.0/js/mdb.min.js" integrity="sha256-NdbiivsvWt7VYCt6hYNT3h/th9vSTL4EDWeGs5SN3DA=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/masonry-layout@4.2.2/dist/masonry.pkgd.min.js" integrity="sha256-Nn1q/fx0H7SNLZMQ5Hw5JLaTRZp0yILA/FRexe19VdI=" crossorigin="anonymous"></script> <script defer src="https://cdn.jsdelivr.net/npm/imagesloaded@5.0.0/imagesloaded.pkgd.min.js" integrity="sha256-htrLFfZJ6v5udOG+3kNLINIKh2gvoKqwEhHYfTTMICc=" crossorigin="anonymous"></script> <script defer src="/assets/js/masonry.js" type="text/javascript"></script> <script defer src="https://cdn.jsdelivr.net/npm/medium-zoom@1.1.0/dist/medium-zoom.min.js" integrity="sha256-ZgMyDAIYDYGxbcpJcfUnYwNevG/xi9OHKaR/8GK+jWc=" crossorigin="anonymous"></script> <script defer src="/assets/js/zoom.js?85ddb88934d28b74e78031fd54cf8308"></script> <script src="/assets/js/no_defer.js?2781658a0a2b13ed609542042a859126"></script> <script defer src="/assets/js/common.js?e0514a05c5c95ac1a93a8dfd5249b92e"></script> <script defer src="/assets/js/copy_code.js?12775fdf7f95e901d7119054556e495f" type="text/javascript"></script> <script defer src="/assets/js/jupyter_new_tab.js?d9f17b6adc2311cbabd747f4538bb15f"></script> <script async src="https://d1bxh8uas1mnw7.cloudfront.net/assets/embed.js"></script> <script async src="https://badge.dimensions.ai/badge.js"></script> <script type="text/javascript">window.MathJax={tex:{tags:"ams"}};</script> <script defer type="text/javascript" id="MathJax-script" src="https://cdn.jsdelivr.net/npm/mathjax@3.2.2/es5/tex-mml-chtml.js" integrity="sha256-MASABpB4tYktI2Oitl4t+78w/lyA+D7b/s9GEP0JOGI=" crossorigin="anonymous"></script> <script defer src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6" crossorigin="anonymous"></script> <script async src="https://www.googletagmanager.com/gtag/js?id=G-Q9WDH7ENSQ"></script> <script>function gtag(){window.dataLayer.push(arguments)}window.dataLayer=window.dataLayer||[],gtag("js",new Date),gtag("config","G-Q9WDH7ENSQ");</script> <script type="text/javascript">function progressBarSetup(){"max"in document.createElement("progress")?(initializeProgressElement(),$(document).on("scroll",function(){progressBar.attr({value:getCurrentScrollPosition()})}),$(window).on("resize",initializeProgressElement)):(resizeProgressBar(),$(document).on("scroll",resizeProgressBar),$(window).on("resize",resizeProgressBar))}function getCurrentScrollPosition(){return $(window).scrollTop()}function initializeProgressElement(){let e=$("#navbar").outerHeight(!0);$("body").css({"padding-top":e}),$("progress-container").css({"padding-top":e}),progressBar.css({top:e}),progressBar.attr({max:getDistanceToScroll(),value:getCurrentScrollPosition()})}function getDistanceToScroll(){return $(document).height()-$(window).height()}function resizeProgressBar(){progressBar.css({width:getWidthPercentage()+"%"})}function getWidthPercentage(){return getCurrentScrollPosition()/getDistanceToScroll()*100}const progressBar=$("#progress");window.onload=function(){setTimeout(progressBarSetup,50)};</script> <script src="/assets/js/vanilla-back-to-top.min.js?f40d453793ff4f64e238e420181a1d17"></script> <script>addBackToTop();</script> <script type="module" src="/assets/js/search/ninja-keys.min.js?a3446f084dcaecc5f75aa1757d087dcf"></script> <ninja-keys hidebreadcrumbs noautoloadmdicons placeholder="Type to start searching"></ninja-keys> <script>let searchTheme=determineComputedTheme();const ninjaKeys=document.querySelector("ninja-keys");"dark"===searchTheme?ninjaKeys.classList.add("dark"):ninjaKeys.classList.remove("dark");const openSearchModal=()=>{const e=$("#navbarNav");e.hasClass("show")&&e.collapse("hide"),ninjaKeys.open()};</script> <script>const ninja=document.querySelector("ninja-keys");ninja.data=[{id:"nav-about",title:"about",section:"Navigation",handler:()=>{window.location.href="/"}},{id:"nav-blog",title:"blog",description:"",section:"Navigation",handler:()=>{window.location.href="/blog/"}},{id:"nav-publications",title:"publications",description:"publications by categories in reversed chronological order. generated by jekyll-scholar.",section:"Navigation",handler:()=>{window.location.href="/publications/"}},{id:"nav-projects",title:"projects",description:"",section:"Navigation",handler:()=>{window.location.href="/projects/"}},{id:"nav-cv",title:"cv",description:"",section:"Navigation",handler:()=>{window.location.href="/cv/"}},{id:"nav-teaching",title:"teaching",description:"",section:"Navigation",handler:()=>{window.location.href="/teaching/"}},{id:"post-modeling-the-reinforcement-learning-problem",title:"Modeling the Reinforcement Learning Problem",description:"My notes on the second chapter of &#39;Grokking Deep Reinforcement Learning&#39; by Miguel Morales. This post covers the components of the environment and how to model it using Markov Decision Processes (MDPs).",section:"Posts",handler:()=>{window.location.href="/blog/2023/modeling-reinforcement-learning-problem/"}},{id:"post-introduction-to-deep-reinforcement-learning",title:"Introduction to Deep Reinforcement Learning",description:"My notes on Deep Reinforcement Learning (DRL) based on the first chapter of the &#39;Grokking Deep Reinforcement Learning&#39; by Miguel Morales.",section:"Posts",handler:()=>{window.location.href="/blog/2023/introduction-to-deep-reinforcement-learning/"}},{id:"post-from-paper-to-code-a-guide-to-implement-research",title:"From Paper to Code: A Guide to Implement Research",description:"This guide covers effective reading, model implementation, code validation, and the power of repetition.",section:"Posts",handler:()=>{window.location.href="/blog/2023/translating-theory-into-code/"}},{id:"post-neural-network-the-universal-function",title:"Neural network: The universal function",description:"",section:"Posts",handler:()=>{window.location.href="/blog/2023/the-universal-function/"}},{id:"news-won-3rd-place-in-the-toyota-challenge-at-wehack-2022",title:"Won 3rd place in the Toyota challenge at WeHack 2022",description:"",section:"News"},{id:"news-won-3rd-place-in-the-cbre-challenge-at-hackutd-ix",title:"Won 3rd place in the CBRE challenge at HackUTD IX",description:"",section:"News"},{id:"news-won-1st-place-in-the-patient-safety-challenge-at-hackutd-x",title:"Won 1st place in the Patient Safety challenge at HackUTD X",description:"",section:"News"},{id:"news-awarded-best-use-of-ai-in-education-at-tamuhack-x",title:"Awarded Best Use of AI in Education at TamuHack X",description:"",section:"News"},{id:"news-awarded-the-jonsson-school-undergraduate-research-award",title:"Awarded the Jonsson School Undergraduate Research Award",description:"",section:"News"},{id:"projects-eco",title:"Eco",description:"Support eco-friendly projects by funding projects.",section:"Projects",handler:()=>{window.location.href="/projects/eco/"}},{id:"projects-random-leetcode",title:"Random Leetcode",description:"A website that randomly select a leetcode question from the blind 75 list.",section:"Projects",handler:()=>{window.location.href="/projects/random-leetcode/"}},{id:"projects-ambient",title:"Ambient",description:"Analyze customer service calls to get an overview of your service quality and effectiveness.",section:"Projects",handler:()=>{window.location.href="/projects/ambient/"}},{id:"projects-letter-grade-calculator",title:"Letter Grade Calculator",description:"A script that let&#39;s you caclulate your class&#39;s letter grade from your scores and the weightings of you scores.",section:"Projects",handler:()=>{window.location.href="/projects/grade-calculator/"}},{id:"projects-robo-rev",title:"Robo Rev",description:"Train your own robotic dog companion with voice recognition and object detection abilities.",section:"Projects",handler:()=>{window.location.href="/projects/robo-rev/"}},{id:"projects-wavenet-implementation",title:"WaveNet Implementation",description:"An implementation of an unconditioned wavenet architecture.",section:"Projects",handler:()=>{window.location.href="/projects/wavenet/"}},{id:"projects-fintuned-speech-emotion-recognition",title:"Fintuned Speech Emotion Recognition",description:"Fine tuned a ResNet image classifer on the speech emotion recongition task.",section:"Projects",handler:()=>{window.location.href="/projects/ser/"}},{id:"projects-bookify",title:"Bookify",description:"Convert book and research paper titles to audio formats for easy listening. Perfect for busy individuals or those with visual impairments.",section:"Projects",handler:()=>{window.location.href="/projects/bookify/"}},{id:"projects-optimine",title:"Optimine",description:"A website that mined data from twitter for specific topics and analyzed their sentiments.",section:"Projects",handler:()=>{window.location.href="/projects/optimine/"}},{id:"projects-fastspeech-1-2",title:"Fastspeech 1 / 2",description:"A pytorch implementation of the FastSpeech architecture trained on the text-to-speech task.",section:"Projects",handler:()=>{window.location.href="/projects/fastspeech/"}},{id:"projects-simple-gridworld",title:"Simple Gridworld",description:"A gridworld used for training reinforcement learning algorithms using the openai&#39;s gym library.",section:"Projects",handler:()=>{window.location.href="/projects/gridworld/"}},{id:"projects-multi-armed-bandits",title:"Multi Armed Bandits",description:"A library contained Multi-Armed Bandit environments built ontop of openai&#39;s gym library.",section:"Projects",handler:()=>{window.location.href="/projects/mab/"}},{id:"projects-reinforcement-learning-algorithms",title:"Reinforcement Learning Algorithms",description:"A library filled with my implentation of reinforcement learning algorithms.",section:"Projects",handler:()=>{window.location.href="/projects/rl-algos/"}},{id:"projects-paper-leaderboard",title:"Paper Leaderboard",description:"We help you find the latest and most promising research papers through a community-driven leaderboard",section:"Projects",handler:()=>{window.location.href="/projects/paperleaderboard/"}},{id:"projects-create-your-demo",title:"Create Your Demo",description:"A studio to create voiceovers for demos.",section:"Projects",handler:()=>{window.location.href="/projects/createdemo/"}},{id:"projects-cs-resume-builder",title:"CS Resume Builder",description:"We give you personalized resume reviews to help you pass the resume screening process.",section:"Projects",handler:()=>{window.location.href="/projects/cs-resume/"}},{id:"projects-curis",title:"Curis",description:"Seeks to keep physicians informed about the best course of action for their patients. The project specifically focuses on Cancer patients and finds relevant medical trials for the patient.",section:"Projects",handler:()=>{window.location.href="/projects/curis/"}},{id:"projects-ddqn-for-atari",title:"DDQN for Atari",description:"Implemented the Double DQN (DDQN) reinforcement learning method for Atari environments in OpenAI Gym.",section:"Projects",handler:()=>{window.location.href="/projects/dqn-atari/"}},{id:"projects-discovery",title:"Discovery",description:"Teaching through discovery ficition generated on the fly using LLMs.",section:"Projects",handler:()=>{window.location.href="/projects/discovery/"}},{id:"projects-prescribe",title:"PreScribe",description:"Records a conversation between the doctor and the patient and transcribes it. While also giving a checklist of prescribed medications requirements to assist doctor in getting the correct medication history for each patient.",section:"Projects",handler:()=>{window.location.href="/projects/prescribe/"}},{id:"socials-email",title:"Send email",section:"Socials",handler:()=>{window.open("mailto:%61%68%61%64.%6A%61%77%61%69%64@%75%74%64%61%6C%6C%61%73.%65%64%75","_blank")}},{id:"socials-google-scholar",title:"Google Scholar",section:"Socials",handler:()=>{window.open("https://scholar.google.com/citations?user=IKtwsQ8AAAAJ","_blank")}},{id:"socials-linkedin",title:"LinkedIn",section:"Socials",handler:()=>{window.open("https://www.linkedin.com/in/ahad-jawaid","_blank")}},{id:"light-theme",title:"Change theme to light",description:"Change the theme of the site to Light",section:"Theme",handler:()=>{setThemeSetting("light")}},{id:"dark-theme",title:"Change theme to dark",description:"Change the theme of the site to Dark",section:"Theme",handler:()=>{setThemeSetting("dark")}},{id:"system-theme",title:"Use system default theme",description:"Change the theme of the site to System Default",section:"Theme",handler:()=>{setThemeSetting("system")}}];</script> <script src="/assets/js/shortcut-key.js?6f508d74becd347268a7f822bca7309d"></script> </body> </html>